{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18dead9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "22/05/12 11:24:15 INFO SparkContext: Running Spark version 3.2.0\n",
      "22/05/12 11:24:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/12 11:24:15 INFO ResourceUtils: ==============================================================\n",
      "22/05/12 11:24:15 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "22/05/12 11:24:15 INFO ResourceUtils: ==============================================================\n",
      "22/05/12 11:24:15 INFO SparkContext: Submitted application: 4b5db212-4396-4158-a2d0-968178fb5ef2\n",
      "22/05/12 11:24:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "22/05/12 11:24:15 INFO ResourceProfile: Limiting resource is cpu\n",
      "22/05/12 11:24:15 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "22/05/12 11:24:15 INFO SecurityManager: Changing view acls to: oscar\n",
      "22/05/12 11:24:15 INFO SecurityManager: Changing modify acls to: oscar\n",
      "22/05/12 11:24:15 INFO SecurityManager: Changing view acls groups to: \n",
      "22/05/12 11:24:15 INFO SecurityManager: Changing modify acls groups to: \n",
      "22/05/12 11:24:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oscar); groups with view permissions: Set(); users  with modify permissions: Set(oscar); groups with modify permissions: Set()\n",
      "22/05/12 11:24:15 INFO Utils: Successfully started service 'sparkDriver' on port 37685.\n",
      "22/05/12 11:24:15 INFO SparkEnv: Registering MapOutputTracker\n",
      "22/05/12 11:24:15 INFO SparkEnv: Registering BlockManagerMaster\n",
      "22/05/12 11:24:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "22/05/12 11:24:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "22/05/12 11:24:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/05/12 11:24:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-34ad8349-524d-4f26-a5c6-22b26a85f74d\n",
      "22/05/12 11:24:15 INFO MemoryStore: MemoryStore started with capacity 4.0 GiB\n",
      "22/05/12 11:24:15 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "22/05/12 11:24:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "22/05/12 11:24:15 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://netrunner:4040\n",
      "22/05/12 11:24:15 INFO Executor: Starting executor ID driver on host netrunner\n",
      "22/05/12 11:24:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42531.\n",
      "22/05/12 11:24:15 INFO NettyBlockTransferService: Server created on netrunner:42531\n",
      "22/05/12 11:24:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "22/05/12 11:24:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, netrunner, 42531, None)\n",
      "22/05/12 11:24:15 INFO BlockManagerMasterEndpoint: Registering block manager netrunner:42531 with 4.0 GiB RAM, BlockManagerId(driver, netrunner, 42531, None)\n",
      "22/05/12 11:24:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, netrunner, 42531, None)\n",
      "22/05/12 11:24:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, netrunner, 42531, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{functions => func, _}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.slf4j.LoggerFactory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@784c0404\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.2.0`\n",
    "import $ivy.`sh.almond::almond-spark:0.10.1`\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "val spark = SparkSession\n",
    "      .builder()\n",
    "      .config(\"spark.sql.shuffle.partitions\", 4)\n",
    "      .master(\"local[4]\")\n",
    "      .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0b3e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mentiretable\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CMPLNT_NUM: string, CMPLNT_FR_DT: string ... 24 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val entiretable = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/police/NYPD_Complaint_Data_Historic.csv\")    \n",
    "    .withColumn(\"CMPLNT_FR_DATETIME\", to_timestamp(concat(col(\"CMPLNT_FR_DT\"), lit(\" \"), col(\"CMPLNT_FR_TM\")), \"MM/dd/yyyy HH:mm:ss\"))\n",
    "    .withColumn(\"COMPLETE_LOC\", concat(col(\"LOC_OF_OCCUR_DESC\"), lit(\" \"), col(\"PREM_TYP_DESC\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ccedca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcrimesManh\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CMPLNT_FR_DATETIME_MANH: timestamp, CMPLNT_FR_DATETIME_2H_AFTER_MANH: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val crimesManh = entiretable\n",
    "    .withColumn(\"CMPLNT_FR_DATETIME_2H_AFTER\", col(\"CMPLNT_FR_DATETIME\") + expr(\"INTERVAL 2 HOURS\"))\n",
    "    .where((col(\"BORO_NM\") === \"MANHATTAN\" || col(\"BORO_NM\") === \"BRONX\") && year(col(\"CMPLNT_FR_DATETIME\")) === 2015)\n",
    "    .withColumnRenamed(\"CMPLNT_FR_DATETIME\", \"CMPLNT_FR_DATETIME_MANH\")\n",
    "    .withColumnRenamed(\"CMPLNT_FR_DATETIME_2H_AFTER\", \"CMPLNT_FR_DATETIME_2H_AFTER_MANH\")\n",
    "    .withColumnRenamed(\"CMPLNT_FR_DT\", \"CMPLNT_FR_DT_MANH\")\n",
    "    .withColumnRenamed(\"CMPLNT_NUM\", \"CMPLNT_NUM_MANH\")\n",
    "    .select(\"CMPLNT_FR_DATETIME_MANH\", \"CMPLNT_FR_DATETIME_2H_AFTER_MANH\", \"CMPLNT_FR_DT_MANH\", \"CMPLNT_NUM_MANH\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec1deb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcrimesQue\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CMPLNT_FR_DATETIME_QUE: timestamp, CMPLNT_FR_DATETIME_2H_AFTER_QUE: timestamp ... 2 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val crimesQue = entiretable\n",
    "    .withColumn(\"CMPLNT_FR_DATETIME_2H_AFTER_QUE\", col(\"CMPLNT_FR_DATETIME\") + expr(\"INTERVAL 2 HOURS\"))\n",
    "    .where((col(\"BORO_NM\") === \"QUEENS\" || col(\"BORO_NM\") === \"BROOKLYN\") && year(col(\"CMPLNT_FR_DATETIME\")) === 2015)\n",
    "    .withColumnRenamed(\"CMPLNT_FR_DATETIME\", \"CMPLNT_FR_DATETIME_QUE\")\n",
    "    .withColumnRenamed(\"CMPLNT_FR_DATETIME_2H_AFTER\", \"CMPLNT_FR_DATETIME_2H_AFTER_QUE\")\n",
    "    .withColumnRenamed(\"CMPLNT_FR_DT\", \"CMPLNT_FR_DT_QUE\")\n",
    "    .withColumnRenamed(\"CMPLNT_NUM\", \"CMPLNT_NUM_QUE\")\n",
    "    .select(\"CMPLNT_FR_DATETIME_QUE\", \"CMPLNT_FR_DATETIME_2H_AFTER_QUE\", \"CMPLNT_FR_DT_QUE\", \"CMPLNT_NUM_QUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd42a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "//crimesQue.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c8222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mresults\u001b[39m: \u001b[32mDataFrame\u001b[39m = [CMPLNT_FR_DATETIME_MANH: timestamp, CMPLNT_NUM_MANH: string ... 2 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = crimesManh\n",
    "    .join(crimesQue, crimesManh.col(\"CMPLNT_FR_DT_MANH\") === crimesQue.col(\"CMPLNT_FR_DT_QUE\"), \"fullouter\")\n",
    "    .where(col(\"CMPLNT_FR_DATETIME_QUE\") <= col(\"CMPLNT_FR_DATETIME_2H_AFTER_MANH\") &&\n",
    "               col(\"CMPLNT_FR_DATETIME_QUE\") >= col(\"CMPLNT_FR_DATETIME_MANH\"))\n",
    "    .select(\"CMPLNT_FR_DATETIME_MANH\", \"CMPLNT_NUM_MANH\", \"CMPLNT_FR_DATETIME_QUE\", \"CMPLNT_NUM_QUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcd2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write.mode(\"overwrite\").parquet(\"../out/police.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b7f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
