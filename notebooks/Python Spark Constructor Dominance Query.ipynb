{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc90d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/02 22:14:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/02 22:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/06/02 22:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "      .config(\"spark.sql.shuffle.partitions\", 4)\\\n",
    "      .master(\"local[4]\")\\\n",
    "      .getOrCreate()\\\n",
    "\n",
    "lastRace = Window.partitionBy(\"year\")\\\n",
    "\n",
    "constructorWindow = Window.partitionBy(\"constructorId\")\\\n",
    "\n",
    "lastRaces = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .load(\"../data/races.csv\")\\\n",
    "    .where((F.col(\"year\") >= 1990) & (F.col(\"year\") <= 1999))\\\n",
    "    .withColumn(\"round\", F.col(\"round\").cast(T.IntegerType()))\\\n",
    "    .withColumn(\"max\", F.max(F.col(\"round\")).over(lastRace))\\\n",
    "    .where(F.col(\"round\") == F.col(\"max\"))\\\n",
    "    .select(\"raceId\", \"year\")\\\n",
    "\n",
    "constructorMap = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .load(\"../data/constructors.csv\")\\\n",
    "    .select(\"constructorId\", \"name\")\\\n",
    "\n",
    "results = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .load(\"../data/constructor_standings.csv\")\\\n",
    "    .join(lastRaces, [\"raceId\"], \"right\")\\\n",
    "    .where(F.col(\"position\") == 1)\\\n",
    "    .select(\"constructorId\", \"wins\", \"year\")\\\n",
    "    .withColumn(\"totalChampWins\", \n",
    "                F.count(F.col(\"constructorId\")).over(constructorWindow).cast(T.IntegerType()))\\\n",
    "    .withColumn(\"totalRaceWins\", \n",
    "                F.sum(F.col(\"wins\")).over(constructorWindow).cast(T.IntegerType()))\\\n",
    "    .dropDuplicates([\"constructorId\"])\\\n",
    "    .join(constructorMap, \"constructorId\")\\\n",
    "    .select(\"totalChampWins\", \"totalRaceWins\", \"name\")\\\n",
    "    .orderBy(F.col(\"totalChampWins\").desc(), F.col(\"totalRaceWins\").desc())\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a872350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+--------+\n",
      "|totalChampWins|totalRaceWins|    name|\n",
      "+--------------+-------------+--------+\n",
      "|             5|           47|Williams|\n",
      "|             3|           23| McLaren|\n",
      "|             1|           11|Benetton|\n",
      "|             1|            6| Ferrari|\n",
      "+--------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastRace = Window.partitionBy(\"year\")\n",
    "\n",
    "# lastRaces = spark.read.format(\"csv\")\\\n",
    "#     .option(\"header\", \"true\")\\\n",
    "#     .option(\"sep\", \",\")\\\n",
    "#     .load(\"../data/races.csv\")\\\n",
    "#     .where((F.col(\"year\") >= 1990) & (F.col(\"year\") <= 1999))\\\n",
    "#     .withColumn(\"round\", F.col(\"round\").cast(T.IntegerType()))\\\n",
    "#     .withColumn(\"max\", F.max(F.col(\"round\")).over(lastRace))\\\n",
    "#     .where(F.col(\"round\") == F.col(\"max\"))\\\n",
    "#     .select(\"raceId\", \"year\")\n",
    "\n",
    "# constructors = Window.partitionBy(\"constructorId\")\n",
    "\n",
    "# constructorWinners = spark.read.format(\"csv\")\\\n",
    "#     .option(\"header\", \"true\")\\\n",
    "#     .option(\"sep\", \",\")\\\n",
    "#     .load(\"../data/constructor_standings.csv\")\\\n",
    "#     .join(lastRaces, [\"raceId\"], \"right\")\\\n",
    "#     .where(F.col(\"position\") == 1)\\\n",
    "#     .select(\"constructorId\", \"wins\", \"year\")\\\n",
    "#     .withColumn(\"totalChampWins\", F.count(F.col(\"constructorId\")).over(constructors))\\\n",
    "#     .withColumn(\"totalRaceWins\", F.sum(F.col(\"wins\")).over(constructors).cast(T.IntegerType()))\\\n",
    "#     .drop(\"wins\")  \n",
    "\n",
    "# constructors = spark.read.format(\"csv\")\\\n",
    "#     .option(\"header\", \"true\")\\\n",
    "#     .option(\"sep\", \",\")\\\n",
    "#     .load(\"../data/constructors.csv\")\\\n",
    "#     .select(\"constructorId\", \"name\")\n",
    "\n",
    "\n",
    "# results = constructorWinners\\\n",
    "#     .drop(\"year\")\\\n",
    "#     .dropDuplicates([\"constructorId\"])\\\n",
    "#     .join(constructors, \"constructorId\")\\\n",
    "#     .sort(F.col(\"totalChampWins\").desc(), F.col(\"totalRaceWins\").desc())\\\n",
    "#     .drop(\"constructorId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7728c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# def current_milli_time():\n",
    "#     return round(time.time() * 1000)\n",
    "\n",
    "# def run():\n",
    "#     start = current_milli_time()\n",
    "#     results.collect()\n",
    "#     return current_milli_time() - start\n",
    "\n",
    "# def average(l):\n",
    "#     return sum(l)/len(l)\n",
    "    \n",
    "# def time_test():\n",
    "#     l = list()\n",
    "#     for i in range(1):\n",
    "#         l.append(run())\n",
    "#     return average(l)\n",
    "\n",
    "# res = time_test()\n",
    "\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28403101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
