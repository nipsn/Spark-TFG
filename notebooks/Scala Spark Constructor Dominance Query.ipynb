{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc90d563",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "22/06/02 22:04:54 INFO SparkContext: Running Spark version 3.2.0\n",
      "22/06/02 22:04:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/02 22:04:54 INFO ResourceUtils: ==============================================================\n",
      "22/06/02 22:04:54 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "22/06/02 22:04:54 INFO ResourceUtils: ==============================================================\n",
      "22/06/02 22:04:54 INFO SparkContext: Submitted application: 5679b4dc-1162-44c4-9abd-658cc986f1c5\n",
      "22/06/02 22:04:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "22/06/02 22:04:54 INFO ResourceProfile: Limiting resource is cpu\n",
      "22/06/02 22:04:54 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "22/06/02 22:04:54 INFO SecurityManager: Changing view acls to: oscar\n",
      "22/06/02 22:04:54 INFO SecurityManager: Changing modify acls to: oscar\n",
      "22/06/02 22:04:54 INFO SecurityManager: Changing view acls groups to: \n",
      "22/06/02 22:04:54 INFO SecurityManager: Changing modify acls groups to: \n",
      "22/06/02 22:04:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oscar); groups with view permissions: Set(); users  with modify permissions: Set(oscar); groups with modify permissions: Set()\n",
      "22/06/02 22:04:54 INFO Utils: Successfully started service 'sparkDriver' on port 35725.\n",
      "22/06/02 22:04:54 INFO SparkEnv: Registering MapOutputTracker\n",
      "22/06/02 22:04:54 INFO SparkEnv: Registering BlockManagerMaster\n",
      "22/06/02 22:04:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "22/06/02 22:04:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "22/06/02 22:04:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/06/02 22:04:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-332c328d-ac0a-4c91-ae48-95d144c47f8c\n",
      "22/06/02 22:04:54 INFO MemoryStore: MemoryStore started with capacity 4.0 GiB\n",
      "22/06/02 22:04:54 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "22/06/02 22:04:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/06/02 22:04:54 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "22/06/02 22:04:54 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://netrunner:4041\n",
      "22/06/02 22:04:55 INFO Executor: Starting executor ID driver on host netrunner\n",
      "22/06/02 22:04:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33015.\n",
      "22/06/02 22:04:55 INFO NettyBlockTransferService: Server created on netrunner:33015\n",
      "22/06/02 22:04:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "22/06/02 22:04:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, netrunner, 33015, None)\n",
      "22/06/02 22:04:55 INFO BlockManagerMasterEndpoint: Registering block manager netrunner:33015 with 4.0 GiB RAM, BlockManagerId(driver, netrunner, 33015, None)\n",
      "22/06/02 22:04:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, netrunner, 33015, None)\n",
      "22/06/02 22:04:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, netrunner, 33015, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{SparkSession, DataFrame}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.slf4j.LoggerFactory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@485314f2\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.2.0`\n",
    "import $ivy.`sh.almond::almond-spark:0.10.1`\n",
    "\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "val spark = SparkSession\n",
    "      .builder()\n",
    "      .config(\"spark.sql.shuffle.partitions\", 4)\n",
    "      .master(\"local[4]\")\n",
    "      .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cdf6e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mconstructorQuery\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def constructorQuery(races: DataFrame, \n",
    "                     constructor_standings: DataFrame, \n",
    "                     constructors: DataFrame\n",
    "                    ): DataFrame = {\n",
    "    \n",
    "\n",
    "    val lastRace = Window.partitionBy(\"year\")\n",
    "\n",
    "    val lastRaces = races\n",
    "        .where(col(\"year\") >= 1990 && col(\"year\") <= 1999)\n",
    "        .withColumn(\"round\", col(\"round\").cast(IntegerType))\n",
    "        .withColumn(\"max\", max(col(\"round\")).over(lastRace))\n",
    "        .where(col(\"round\") === col(\"max\"))\n",
    "        .select(\"raceId\", \"year\")\n",
    "    \n",
    "    val constructorMap = constructors\n",
    "        .select(\"constructorId\", \"name\")\n",
    "    \n",
    "    val constructorWindow = Window.partitionBy(\"constructorId\")\n",
    "\n",
    "    constructor_standings\n",
    "        .join(lastRaces, Seq(\"raceId\"), \"right\")\n",
    "        .where(col(\"position\") === 1)\n",
    "        .withColumn(\"totalChampWins\", \n",
    "                    count(col(\"constructorId\")).over(constructorWindow))\n",
    "        .withColumn(\"totalRaceWins\", \n",
    "                    sum(col(\"wins\")).over(constructorWindow))\n",
    "        .dropDuplicates(\"constructorId\")\n",
    "        .join(constructorMap, \"constructorId\")\n",
    "        .select(\"totalChampWins\", \"totalRaceWins\", \"name\")\n",
    "        .orderBy(col(\"totalChampWins\").desc, col(\"totalRaceWins\").desc)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35186ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+--------+\n",
      "|totalChampWins|totalRaceWins|    name|\n",
      "+--------------+-------------+--------+\n",
      "|             5|         47.0|Williams|\n",
      "|             3|         23.0| McLaren|\n",
      "|             1|         11.0|Benetton|\n",
      "|             1|          6.0| Ferrari|\n",
      "+--------------+-------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mraces\u001b[39m: \u001b[32mDataFrame\u001b[39m = [raceId: string, year: string ... 6 more fields]\n",
       "\u001b[36mconstructor_standings\u001b[39m: \u001b[32mDataFrame\u001b[39m = [constructorStandingsId: string, raceId: string ... 5 more fields]\n",
       "\u001b[36mconstructors\u001b[39m: \u001b[32mDataFrame\u001b[39m = [constructorId: string, constructorRef: string ... 3 more fields]\n",
       "\u001b[36mresults\u001b[39m: \u001b[32mDataFrame\u001b[39m = [totalChampWins: bigint, totalRaceWins: double ... 1 more field]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val races = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/races.csv\")\n",
    "\n",
    "val constructor_standings = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/constructor_standings.csv\")\n",
    "\n",
    "val constructors = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/constructors.csv\")\n",
    "\n",
    "val results = constructorQuery(races, constructor_standings, constructors)\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83257eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
       "\n",
       "// restrict the output height to avoid scrolling in output cells\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.plotly-scala::plotly-almond:0.7.0`\n",
    "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
    "\n",
    "// restrict the output height to avoid scrolling in output cells\n",
    "repl.pprinter() = repl.pprinter().copy(defaultHeight = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486ad9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <script type=\"text/javascript\">\n",
       "        require.config({\n",
       "  paths: {\n",
       "    d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min',\n",
       "    plotly: 'https://cdn.plot.ly/plotly-1.41.3.min',\n",
       "    jquery: 'https://code.jquery.com/jquery-3.3.1.min'\n",
       "  },\n",
       "\n",
       "  shim: {\n",
       "    plotly: {\n",
       "      deps: ['d3', 'jquery'],\n",
       "      exports: 'plotly'\n",
       "    }\n",
       "  }\n",
       "});\n",
       "        \n",
       "\n",
       "        require(['plotly'], function(Plotly) {\n",
       "          window.Plotly = Plotly;\n",
       "        });\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          "Williams",
          "McLaren",
          "Benetton",
          "Ferrari"
         ],
         "y": [
          "47.0",
          "23.0",
          "11.0",
          "6.0"
         ]
        }
       ],
       "layout": {
        "barmode": "group"
       }
      },
      "text/html": [
       "<div class=\"chart\" id=\"plot-c3662ce2-b24f-496e-baa3-98477dd5bba2\"></div>\n",
       "<script>require(['plotly'], function(Plotly) {\n",
       "  (function () {\n",
       "  var data0 = {\"x\":[\"Williams\",\"McLaren\",\"Benetton\",\"Ferrari\"],\"y\":[\"47.0\",\"23.0\",\"11.0\",\"6.0\"],\"type\":\"bar\"};\n",
       "\n",
       "  var data = [data0];\n",
       "  var layout = {\"barmode\":\"group\"};\n",
       "\n",
       "  Plotly.plot('plot-c3662ce2-b24f-496e-baa3-98477dd5bba2', data, layout);\n",
       "})();\n",
       "});\n",
       "      </script>\n",
       "           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mconstructors\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"Williams\"\u001b[39m, \u001b[32m\"McLaren\"\u001b[39m, \u001b[32m\"Benetton\"\u001b[39m, \u001b[32m\"Ferrari\"\u001b[39m)\n",
       "\u001b[36mraceWins\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"47.0\"\u001b[39m, \u001b[32m\"23.0\"\u001b[39m, \u001b[32m\"11.0\"\u001b[39m, \u001b[32m\"6.0\"\u001b[39m)\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mBar\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[33mBar\u001b[39m(\n",
       "...\n",
       "\u001b[36mlayout\u001b[39m: \u001b[32mLayout\u001b[39m = \u001b[33mLayout\u001b[39m(\n",
       "  \u001b[32mNone\u001b[39m,\n",
       "...\n",
       "\u001b[36mres4_4\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"plot-c3662ce2-b24f-496e-baa3-98477dd5bba2\"\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val constructors = results\n",
    "    .select(\"name\")\n",
    "    .as[String]\n",
    "    .collect()\n",
    "    .toList\n",
    "\n",
    "val raceWins = results\n",
    "    .select(\"totalRaceWins\")\n",
    "    .as[String]\n",
    "    .collect()\n",
    "    .toList\n",
    "\n",
    "val data = Seq(Bar(constructors, raceWins))\n",
    "\n",
    "val layout = Layout(barmode = BarMode.Group)\n",
    "\n",
    "plot(data, layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f601e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
