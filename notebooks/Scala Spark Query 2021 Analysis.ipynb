{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc90d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n",
      "Getting spark JARs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "21/12/06 17:46:47 INFO SparkContext: Running Spark version 2.4.3\n",
      "21/12/06 17:46:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "21/12/06 17:46:47 INFO SparkContext: Submitted application: ff900165-02c0-46aa-a654-31166592204d\n",
      "21/12/06 17:46:47 INFO SecurityManager: Changing view acls to: oscar\n",
      "21/12/06 17:46:47 INFO SecurityManager: Changing modify acls to: oscar\n",
      "21/12/06 17:46:47 INFO SecurityManager: Changing view acls groups to: \n",
      "21/12/06 17:46:47 INFO SecurityManager: Changing modify acls groups to: \n",
      "21/12/06 17:46:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(oscar); groups with view permissions: Set(); users  with modify permissions: Set(oscar); groups with modify permissions: Set()\n",
      "21/12/06 17:46:48 INFO Utils: Successfully started service 'sparkDriver' on port 43363.\n",
      "21/12/06 17:46:48 INFO SparkEnv: Registering MapOutputTracker\n",
      "21/12/06 17:46:48 INFO SparkEnv: Registering BlockManagerMaster\n",
      "21/12/06 17:46:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "21/12/06 17:46:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "21/12/06 17:46:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dc0b3e81-227c-4eb3-87a2-336eabbffb7f\n",
      "21/12/06 17:46:48 INFO MemoryStore: MemoryStore started with capacity 1956.6 MB\n",
      "21/12/06 17:46:48 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "21/12/06 17:46:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "21/12/06 17:46:48 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://netrunner:4040\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0-sources.jar at spark://netrunner:43363/jars/jvm-repr-0.4.0-sources.jar with timestamp 1638809208703\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0.jar at spark://netrunner:43363/jars/jvm-repr-0.4.0.jar with timestamp 1638809208704\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5-sources.jar at spark://netrunner:43363/jars/javaparser-core-3.2.5-sources.jar with timestamp 1638809208704\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5.jar at spark://netrunner:43363/jars/javaparser-core-3.2.5.jar with timestamp 1638809208704\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12/2.3.8-36-1cce53f3/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar at spark://netrunner:43363/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1638809208705\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler-interface_2.12/2.3.8-36-1cce53f3/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar at spark://netrunner:43363/jars/ammonite-compiler-interface_2.12-2.3.8-36-1cce53f3.jar with timestamp 1638809208705\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.12/2.3.8-36-1cce53f3/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar at spark://netrunner:43363/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1638809208705\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-compiler_2.12.12/2.3.8-36-1cce53f3/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar at spark://netrunner:43363/jars/ammonite-compiler_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1638809208705\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.12/2.3.8-36-1cce53f3/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar at spark://netrunner:43363/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1638809208706\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp-api_2.12.12/2.3.8-36-1cce53f3/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar at spark://netrunner:43363/jars/ammonite-interp-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1638809208706\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-ops_2.12/2.3.8-36-1cce53f3/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar at spark://netrunner:43363/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1638809208706\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-ops_2.12/2.3.8-36-1cce53f3/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar at spark://netrunner:43363/jars/ammonite-ops_2.12-2.3.8-36-1cce53f3.jar with timestamp 1638809208706\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.12/2.3.8-36-1cce53f3/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar at spark://netrunner:43363/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1638809208707\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl-api_2.12.12/2.3.8-36-1cce53f3/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar at spark://netrunner:43363/jars/ammonite-repl-api_2.12.12-2.3.8-36-1cce53f3.jar with timestamp 1638809208707\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/2.3.8-36-1cce53f3/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar at spark://netrunner:43363/jars/ammonite-util_2.12-2.3.8-36-1cce53f3-sources.jar with timestamp 1638809208707\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/2.3.8-36-1cce53f3/ammonite-util_2.12-2.3.8-36-1cce53f3.jar at spark://netrunner:43363/jars/ammonite-util_2.12-2.3.8-36-1cce53f3.jar with timestamp 1638809208707\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.2.9/fansi_2.12-0.2.9-sources.jar at spark://netrunner:43363/jars/fansi_2.12-0.2.9-sources.jar with timestamp 1638809208707\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.2.9/fansi_2.12-0.2.9.jar at spark://netrunner:43363/jars/fansi_2.12-0.2.9.jar with timestamp 1638809208708\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/2.3.0/fastparse_2.12-2.3.0-sources.jar at spark://netrunner:43363/jars/fastparse_2.12-2.3.0-sources.jar with timestamp 1638809208708\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/2.3.0/fastparse_2.12-2.3.0.jar at spark://netrunner:43363/jars/fastparse_2.12-2.3.0.jar with timestamp 1638809208708\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/0.6.7/geny_2.12-0.6.7-sources.jar at spark://netrunner:43363/jars/geny_2.12-0.6.7-sources.jar with timestamp 1638809208708\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/0.6.7/geny_2.12-0.6.7.jar at spark://netrunner:43363/jars/geny_2.12-0.6.7.jar with timestamp 1638809208708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.1.4/mainargs_2.12-0.1.4-sources.jar at spark://netrunner:43363/jars/mainargs_2.12-0.1.4-sources.jar with timestamp 1638809208709\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/mainargs_2.12/0.1.4/mainargs_2.12-0.1.4.jar at spark://netrunner:43363/jars/mainargs_2.12-0.1.4.jar with timestamp 1638809208709\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.7.1/os-lib_2.12-0.7.1-sources.jar at spark://netrunner:43363/jars/os-lib_2.12-0.7.1-sources.jar with timestamp 1638809208709\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.7.1/os-lib_2.12-0.7.1.jar at spark://netrunner:43363/jars/os-lib_2.12-0.7.1.jar with timestamp 1638809208709\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.6.0/pprint_2.12-0.6.0-sources.jar at spark://netrunner:43363/jars/pprint_2.12-0.6.0-sources.jar with timestamp 1638809208709\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.6.0/pprint_2.12-0.6.0.jar at spark://netrunner:43363/jars/pprint_2.12-0.6.0.jar with timestamp 1638809208710\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/2.3.0/scalaparse_2.12-2.3.0-sources.jar at spark://netrunner:43363/jars/scalaparse_2.12-2.3.0-sources.jar with timestamp 1638809208710\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/2.3.0/scalaparse_2.12-2.3.0.jar at spark://netrunner:43363/jars/scalaparse_2.12-2.3.0.jar with timestamp 1638809208710\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.2.3/sourcecode_2.12-0.2.3-sources.jar at spark://netrunner:43363/jars/sourcecode_2.12-0.2.3-sources.jar with timestamp 1638809208710\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.2.3/sourcecode_2.12-0.2.3.jar at spark://netrunner:43363/jars/sourcecode_2.12-0.2.3.jar with timestamp 1638809208711\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.3/interface-1.0.3-sources.jar at spark://netrunner:43363/jars/interface-1.0.3-sources.jar with timestamp 1638809208711\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/interface/1.0.3/interface-1.0.3.jar at spark://netrunner:43363/jars/interface-1.0.3.jar with timestamp 1638809208711\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA-sources.jar at spark://netrunner:43363/jars/javassist-3.21.0-GA-sources.jar with timestamp 1638809208711\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar at spark://netrunner:43363/jars/javassist-3.21.0-GA.jar with timestamp 1638809208711\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.4.3/scala-collection-compat_2.12-2.4.3-sources.jar at spark://netrunner:43363/jars/scala-collection-compat_2.12-2.4.3-sources.jar with timestamp 1638809208712\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.4.3/scala-collection-compat_2.12-2.4.3.jar at spark://netrunner:43363/jars/scala-collection-compat_2.12-2.4.3.jar with timestamp 1638809208712\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/2.0.0-M3/scala-xml_2.12-2.0.0-M3-sources.jar at spark://netrunner:43363/jars/scala-xml_2.12-2.0.0-M3-sources.jar with timestamp 1638809208712\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/2.0.0-M3/scala-xml_2.12-2.0.0-M3.jar at spark://netrunner:43363/jars/scala-xml_2.12-2.0.0-M3.jar with timestamp 1638809208712\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.12.12/scala-compiler-2.12.12-sources.jar at spark://netrunner:43363/jars/scala-compiler-2.12.12-sources.jar with timestamp 1638809208713\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.12/scala-library-2.12.12-sources.jar at spark://netrunner:43363/jars/scala-library-2.12.12-sources.jar with timestamp 1638809208713\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.12/scala-reflect-2.12.12-sources.jar at spark://netrunner:43363/jars/scala-reflect-2.12.12-sources.jar with timestamp 1638809208713\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.11.2/interpreter-api_2.12-0.11.2-sources.jar at spark://netrunner:43363/jars/interpreter-api_2.12-0.11.2-sources.jar with timestamp 1638809208713\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.11.2/interpreter-api_2.12-0.11.2.jar at spark://netrunner:43363/jars/interpreter-api_2.12-0.11.2.jar with timestamp 1638809208713\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.11.2/jupyter-api_2.12-0.11.2-sources.jar at spark://netrunner:43363/jars/jupyter-api_2.12-0.11.2-sources.jar with timestamp 1638809208714\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.11.2/jupyter-api_2.12-0.11.2.jar at spark://netrunner:43363/jars/jupyter-api_2.12-0.11.2.jar with timestamp 1638809208714\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.12/0.11.2/scala-kernel-api_2.12.12-0.11.2-sources.jar at spark://netrunner:43363/jars/scala-kernel-api_2.12.12-0.11.2-sources.jar with timestamp 1638809208714\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.12/0.11.2/scala-kernel-api_2.12.12-0.11.2.jar at spark://netrunner:43363/jars/scala-kernel-api_2.12.12-0.11.2.jar with timestamp 1638809208714\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.local/share/jupyter/kernels/scala212/launcher.jar at spark://netrunner:43363/jars/launcher.jar with timestamp 1638809208714\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.13/scala-library-2.12.13.jar at spark://netrunner:43363/jars/scala-library-2.12.13.jar with timestamp 1638809208715\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/almond-spark_2.12/0.6.0/almond-spark_2.12-0.6.0.jar at spark://netrunner:43363/jars/almond-spark_2.12-0.6.0.jar with timestamp 1638809208715\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/ammonite-spark_2.12/0.5.0/ammonite-spark_2.12-0.5.0.jar at spark://netrunner:43363/jars/ammonite-spark_2.12-0.5.0.jar with timestamp 1638809208715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/argonaut-shapeless_6.2_2.12/1.2.0-M11/argonaut-shapeless_6.2_2.12-1.2.0-M11.jar at spark://netrunner:43363/jars/argonaut-shapeless_6.2_2.12-1.2.0-M11.jar with timestamp 1638809208715\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.jar at spark://netrunner:43363/jars/jetty-server-9.4.19.v20190610.jar with timestamp 1638809208717\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/io/argonaut/argonaut_2.12/6.2.3/argonaut_2.12-6.2.3.jar at spark://netrunner:43363/jars/argonaut_2.12-6.2.3.jar with timestamp 1638809208718\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/com/chuusai/shapeless_2.12/2.3.3/shapeless_2.12-2.3.3.jar at spark://netrunner:43363/jars/shapeless_2.12-2.3.3.jar with timestamp 1638809208718\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.jar at spark://netrunner:43363/jars/jetty-http-9.4.19.v20190610.jar with timestamp 1638809208718\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.jar at spark://netrunner:43363/jars/jetty-io-9.4.19.v20190610.jar with timestamp 1638809208718\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/typelevel/macro-compat_2.12/1.1.1/macro-compat_2.12-1.1.1.jar at spark://netrunner:43363/jars/macro-compat_2.12-1.1.1.jar with timestamp 1638809208719\n",
      "21/12/06 17:46:48 INFO SparkContext: Added JAR file:/home/oscar/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.jar at spark://netrunner:43363/jars/jetty-util-9.4.19.v20190610.jar with timestamp 1638809208719\n",
      "21/12/06 17:46:48 INFO Executor: Starting executor ID driver on host localhost\n",
      "21/12/06 17:46:48 INFO Executor: Using REPL class URI: http://192.168.1.228:43501\n",
      "21/12/06 17:46:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45677.\n",
      "21/12/06 17:46:48 INFO NettyBlockTransferService: Server created on netrunner:45677\n",
      "21/12/06 17:46:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "21/12/06 17:46:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, netrunner, 45677, None)\n",
      "21/12/06 17:46:48 INFO BlockManagerMasterEndpoint: Registering block manager netrunner:45677 with 1956.6 MB RAM, BlockManagerId(driver, netrunner, 45677, None)\n",
      "21/12/06 17:46:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, netrunner, 45677, None)\n",
      "21/12/06 17:46:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, netrunner, 45677, None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://netrunner:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{functions => func, _}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.slf4j.LoggerFactory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@7b9a41e2\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrun\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.3`\n",
    "import $ivy.`sh.almond::almond-spark:0.6.0`\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "val spark = NotebookSparkSession\n",
    "      .builder()\n",
    "      .config(\"spark.sql.join.preferSortMergeJoin\", false)\n",
    "      .config(\"spark.sql.shuffle.partitions\", 64)\n",
    "      .master(\"local[*]\")\n",
    "      .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)\n",
    "\n",
    "def run[A](code: => A): A = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val res = code\n",
    "    println(s\"Took ${System.currentTimeMillis() - start}\")\n",
    "    res\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95df751c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.vegas-viz:vegas_2.11:0.3.11`\n",
    "import $ivy.`org.vegas-viz:vegas-spark_2.11:0.3.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d29ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mvegas._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.render.WindowRenderer._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.sparkExt._\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vegas._\n",
    "import vegas.render.WindowRenderer._\n",
    "import vegas.sparkExt._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2be4ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706bd707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-ea6f07a0-6cd3-45df-a928-c3df75fa0845', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd2.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdrivers\u001b[39m: \u001b[32mDataFrame\u001b[39m = [driverId: string, driverRef: string ... 7 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val drivers = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/drivers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950883cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd3.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mraces\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [raceId: string, year: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val races = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/races.csv\")\n",
    "    .select(\"raceId\", \"year\")\n",
    "    .where(col(\"year\") === 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbb4438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdriverWindow\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@6da6dc6d\n",
       "\u001b[36mseasonWindow\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@64d85422\n",
       "\u001b[36mdriverRaceWindow\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@17728abd"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val driverWindow = Window.partitionBy(\"driverId\")\n",
    "val seasonWindow = Window.partitionBy(\"year\")\n",
    "val driverRaceWindow = Window.partitionBy(\"driverId\", \"raceId\")\n",
    "val raceDriverLapWindow = Window.partitionBy(\"driverId\", \"raceId\").orderBy(\"lap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e436443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd6.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpitStops\u001b[39m: \u001b[32mDataFrame\u001b[39m = [raceId: string, driverId: string ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pitStops = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/pit_stops.csv\")\n",
    "    .withColumn(\"lap\", (col(\"lap\") - 1).cast(IntegerType)) \n",
    "    .join(races, \"raceId\")\n",
    "    .select(\"raceId\", \"driverId\", \"lap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87117fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- raceId: string (nullable = true)\n",
      " |-- driverId: string (nullable = true)\n",
      " |-- lap: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pitStops.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ac4629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd8.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36movertakes\u001b[39m: \u001b[32mDataFrame\u001b[39m = [raceId: string, driverId: string ... 2 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val overtakes = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/lap_times.csv\")\n",
    "    .withColumn(\"position\", col(\"position\").cast(IntegerType)) \n",
    "    .withColumn(\"lap\", col(\"lap\").cast(IntegerType)) \n",
    "    .join(races, \"raceId\")\n",
    "    .join(pitStops, Seq(\"raceId\", \"driverId\", \"lap\"), \"left\")\n",
    "    .withColumn(\"positionNextLap\", lead(col(\"position\"), 1).over(raceDriverLapWindow))\n",
    "    .withColumn(\"positionsGainedLap\", when(col(\"positionNextLap\") < col(\"position\") , abs(col(\"position\") - col(\"positionNextLap\"))).otherwise(0))\n",
    "    .withColumn(\"positionsLostLap\", when(col(\"positionNextLap\") > col(\"position\"), abs(col(\"position\") - col(\"positionNextLap\"))).otherwise(0))\n",
    "    .withColumn(\"positionsGained\", sum(col(\"positionsGainedLap\")).over(driverRaceWindow))\n",
    "    .withColumn(\"positionsLost\", sum(col(\"positionsLostLap\")).over(driverRaceWindow))\n",
    "//     .sort(col(\"lap\"))\n",
    "    .where(col(\"lap\") === 1)\n",
    "    .select(\"raceId\", \"driverId\", \"positionsGained\", \"positionsLost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2468ec96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd12.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mresults\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [code: string, champPoints: bigint ... 9 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"../data/results.csv\")\n",
    "\n",
    "    .withColumn(\"position\", col(\"position\").cast(IntegerType))    \n",
    "    .withColumn(\"grid\", col(\"grid\").cast(IntegerType))    \n",
    "    .withColumn(\"points\", col(\"points\").cast(IntegerType))\n",
    "\n",
    "    .join(races, \"raceId\")\n",
    "    .join(overtakes, Seq(\"raceId\", \"driverId\"), \"left\")\n",
    "    .join(drivers, \"driverId\")\n",
    "\n",
    "    .withColumn(\"podium\", when(col(\"position\") === 1 || col(\"position\") === 2 ||col(\"position\") === 3, lit(1)).otherwise(lit(0)))\n",
    "    .withColumn(\"averagePoints\", round(avg(col(\"points\")).over(driverWindow), 2))\n",
    "    .withColumn(\"maxAvgPoints\", max(col(\"averagePoints\")).over(seasonWindow))\n",
    "\n",
    "    .select(\n",
    "        col(\"code\"),\n",
    "        sum(col(\"points\")).over(driverWindow).as(\"champPoints\"),\n",
    "        col(\"averagePoints\"),\n",
    "        round(col(\"averagePoints\") / col(\"maxAvgPoints\")).as(\"pointPercent\"),\n",
    "        sum(col(\"podium\")).over(driverWindow).as(\"totalPodiums\"),\n",
    "        round(sum(col(\"podium\")).over(driverWindow) / count(col(\"podium\")).over(driverWindow), 2).as(\"podiumPercent\"),\n",
    "        round(avg(col(\"position\") - col(\"grid\")).over(driverWindow), 2).as(\"positionDelta\"),\n",
    "        round(avg(col(\"positionsLost\")).over(driverWindow), 2).as(\"avgPositionsLost\"),\n",
    "        round(avg(col(\"positionsGained\")).over(driverWindow), 2).as(\"avgPositionsWon\"),\n",
    "        sum(col(\"positionsLost\")).over(driverWindow).as(\"totalPositionsLost\"),\n",
    "        sum(col(\"positionsGained\")).over(driverWindow).as(\"totalPositionsWon\")        \n",
    "    )\n",
    "\n",
    "\n",
    "    .dropDuplicates(Seq(\"code\"))\n",
    "    .sort(col(\"champPoints\").desc)\n",
    "//     .show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ec3670e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mvegas._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.render.WindowRenderer._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.sparkExt._\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vegas._\n",
    "import vegas.render.WindowRenderer._\n",
    "import vegas.sparkExt._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e682e460",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mjava.lang.NoClassDefFoundError: Could not initialize class vegas.package$\u001b[39m\n  ammonite.$sess.cmd19$Helper.<init>(\u001b[32mcmd19.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd19$.<init>(\u001b[32mcmd19.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd19$.<clinit>(\u001b[32mcmd19.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "Vegas(\"Average Points\")\n",
    "    .withDataFrame(results)\n",
    "    .mark(Bar)\n",
    "    .encodeX(\"code\", Nom)\n",
    "    .encodeY(\"averagePoints\", Quant)\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b95b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
