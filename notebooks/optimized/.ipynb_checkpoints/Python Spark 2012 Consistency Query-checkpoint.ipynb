{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc90d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/04 21:09:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "      .config(\"spark.sql.shuffle.partitions\", 4)\\\n",
    "      .master(\"local[4]\")\\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228a3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = spark.read.parquet(\"../../data/parquet/races.parquet\")\\\n",
    "    .where(F.col(\"year\") == 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318bf62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798ad2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lapTimeToMs(time:str):\n",
    "    if time == \"\\\\N\":\n",
    "        return 180000\n",
    "    else:\n",
    "        match = re.search(r\"([0-9]|[0-9][0-9]):([0-9][0-9])\\.([0-9][0-9][0-9])\",time)\n",
    "        m = int(match.group(1))\n",
    "        s = int(match.group(2))\n",
    "        ms = int(match.group(3))\n",
    "        return m*60000 + s*1000 + ms\n",
    "\n",
    "lapTimeToMsUDF = F.udf(lapTimeToMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e98c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msToLapTime(time:int):\n",
    "    mins = int(time / 60000)\n",
    "    secs = int((time - int(mins*60000))/1000)\n",
    "    ms = int(time - mins*60000 - secs*1000)\n",
    "\n",
    "    \n",
    "    formattedSecs = \"\"\n",
    "    formattedMs = \"\"\n",
    "    \n",
    "    if int(secs / 10) == 0: formattedSecs = \"0\" + str(secs)\n",
    "    else: formattedSecs = str(secs) \n",
    "        \n",
    "    # if ms = 00x -> \"0\"+\"0\"+x . if ms = 0xx -> \"0\"+ms\n",
    "    if int(ms / 100) == 0: \n",
    "        if int(ms / 10) == 0: \n",
    "            val = \"0\" + str(ms)\n",
    "        else: val = str(ms) \n",
    "            \n",
    "        formattedMs = \"0\" + val\n",
    "    else: formattedMs = ms\n",
    "    return str(mins) + \":\" + formattedSecs + \".\" + str(formattedMs)\n",
    "\n",
    "msToLapTimeUDF = F.udf(msToLapTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "377c153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driverWindow = Window.partitionBy(\"driverId\")\n",
    "\n",
    "avg_lap_times = spark.read.parquet(\"../../data/parquet/lap_times.parquet\")\\\n",
    "    .withColumnRenamed(\"time\", \"lapTime\")\\\n",
    "    .join(races, [\"raceId\"], \"right\")\\\n",
    "    .withColumn(\"milliseconds\", F.col(\"milliseconds\").cast(T.IntegerType()))\\\n",
    "    .withColumn(\"avgMs\", F.avg(F.col(\"milliseconds\")).over(driverWindow))\\\n",
    "    .dropDuplicates([\"driverId\"])\\\n",
    "    .select(\"driverId\", \"avgMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d46d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = spark.read.parquet(\"../../data/parquet/drivers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d058dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonWindow = Window.partitionBy(\"year\")\n",
    "\n",
    "lapCount = spark.read.parquet(\"../../data/parquet/lap_times.parquet\")\\\n",
    "    .join(races, [\"raceId\"], \"right\")\\\n",
    "    .withColumn(\"lapsPerDriver\", F.count(F.col(\"lap\")).over(driverWindow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c30af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = lapCount\\\n",
    "    .agg(\n",
    "        F.countDistinct(\"driverID\"),\n",
    "        F.count(F.col(\"lap\")))\\\n",
    "    .collect()[0]\n",
    "    \n",
    "distinctDrivers = row[0]\n",
    "allLaps = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfb0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgLapsThisPeriod = allLaps / distinctDrivers\n",
    "\n",
    "rowList = lapCount\\\n",
    "    .where(F.col(\"lapsPerDriver\") >= avgLapsThisPeriod)\\\n",
    "    .select(\"driverId\")\\\n",
    "    .distinct()\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b44e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiencedDrivers = []\n",
    "\n",
    "for i in range(0, len(rowList)-1):\n",
    "    experiencedDrivers.append(int(rowList[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9970e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = spark.read.parquet(\"../../data/parquet/results.parquet\")\\\n",
    "    .join(races, [\"raceId\"], \"right\")\\\n",
    "    .na.drop(subset=[\"fastestLapTime\"])\\\n",
    "    .withColumn(\"fastestLapTimeMs\", lapTimeToMsUDF(F.col(\"fastestLapTime\")))\\\n",
    "    .withColumn(\"avgFastestLapMs\", F.avg(F.col(\"fastestLapTimeMs\")).over(driverWindow))\\\n",
    "    .dropDuplicates([\"driverId\"])\\\n",
    "    .join(avg_lap_times, [\"driverId\"], \"left\")\\\n",
    "    .withColumn(\"diffLapTimes\", F.abs(F.col(\"avgMs\") - F.col(\"avgFastestLapMs\")).cast(T.IntegerType()))\\\n",
    "    .withColumn(\"avgDiff\", msToLapTimeUDF(F.col(\"diffLapTimes\").cast(T.IntegerType())))\\\n",
    "    .where(F.col(\"driverId\").isin(experiencedDrivers))\\\n",
    "    .join(drivers, \"driverId\")\\\n",
    "    .withColumn(\"driver\", F.concat(F.col(\"forename\"), F.lit(\" \"), F.col(\"surname\")))\\\n",
    "    .select(\"driver\", \"avgDiff\")\\\n",
    "    .orderBy(\"avgDiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dade28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def current_milli_time():\n",
    "    return round(time.time() * 1000)\n",
    "\n",
    "def run():\n",
    "    start = current_milli_time()\n",
    "    results.collect()\n",
    "    return current_milli_time() - start\n",
    "\n",
    "def average(l):\n",
    "    return sum(l)/len(l)\n",
    "    \n",
    "def time_test():\n",
    "    l = list()\n",
    "    for i in range(1):\n",
    "        l.append(run())\n",
    "    return average(l)\n",
    "\n",
    "res = time_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d2e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
