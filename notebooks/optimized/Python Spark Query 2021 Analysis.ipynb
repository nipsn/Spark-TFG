{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc90d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/04 21:32:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "      .config(\"spark.sql.shuffle.partitions\", 4)\\\n",
    "      .master(\"local[4]\")\\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950883cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = spark.read.parquet(\"../../data/parquet/races.parquet\")\\\n",
    "    .select(\"raceId\", \"year\")\\\n",
    "    .where(F.col(\"year\") == 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706bd707",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = spark.read.parquet(\"../../data/parquet/drivers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbb4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "driverWindow = Window.partitionBy(\"driverId\")\n",
    "seasonWindow = Window.partitionBy(\"year\")\n",
    "driverRaceWindow = Window.partitionBy(\"driverId\", \"raceId\")\n",
    "raceDriverLapWindow = Window.partitionBy(\"driverId\", \"raceId\").orderBy(\"lap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7ccd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:===================================================>   (448 + 4) / 476]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "driverStats = spark.read.parquet(\"../../data/parquet/lap_times.parquet\")\\\n",
    "    .withColumn(\"position\", F.col(\"position\").cast(IntegerType()))\\\n",
    "    .withColumn(\"lap\", F.col(\"lap\").cast(IntegerType()))\\\n",
    "    .join(races, \"raceId\")\\\n",
    "    .withColumn(\"positionNextLap\", F.lead(F.col(\"position\"), 1).over(raceDriverLapWindow))\\\n",
    "    .withColumn(\"positionsGainedLap\", F.when(F.col(\"positionNextLap\") < F.col(\"position\") , F.abs(F.col(\"position\") - F.col(\"positionNextLap\"))).otherwise(0))\\\n",
    "    .withColumn(\"positionsLostLap\", F.when(F.col(\"positionNextLap\") > F.col(\"position\"), F.abs(F.col(\"position\") - F.col(\"positionNextLap\"))).otherwise(0))\\\n",
    "    .withColumn(\"positionsGained\", F.sum(F.col(\"positionsGainedLap\")).over(driverRaceWindow))\\\n",
    "    .withColumn(\"positionsLost\", F.sum(F.col(\"positionsLostLap\")).over(driverRaceWindow))\\\n",
    "    .withColumn(\"lapLeader\", F.when(F.col(\"position\") == 1, 1).otherwise(0))\\\n",
    "    .withColumn(\"lapsLed\", F.sum(F.col(\"lapLeader\")).over(driverWindow))\\\n",
    "    .withColumn(\"totalLaps\", F.sum(F.col(\"lapLeader\")).over(seasonWindow))\\\n",
    "    .withColumn(\"percLapsLed\", F.round(F.col(\"lapsLed\") / F.col(\"totalLaps\"), 2))\\\n",
    "    .select(\"raceId\", \"driverId\", \"positionsGained\", \"positionsLost\", \"lapsLed\", \"percLapsLed\")\\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2468ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results = spark.read.parquet(\"../../data/parquet/results.parquet\")\\\n",
    "    .withColumn(\"position\", F.col(\"position\").cast(T.IntegerType()))\\\n",
    "    .withColumn(\"grid\", F.col(\"grid\").cast(T.IntegerType()))\\\n",
    "    .withColumn(\"points\", F.col(\"points\").cast(T.IntegerType()))\\\n",
    "    .join(races, \"raceId\")\\\n",
    "    .join(driverStats, [\"raceId\", \"driverId\"], \"left\")\\\n",
    "    .join(drivers, \"driverId\")\\\n",
    "    .withColumn(\"podium\", F.when((F.col(\"position\") == 1) | (F.col(\"position\") == 2) | (F.col(\"position\") == 3), F.lit(1)).otherwise(F.lit(0)))\\\n",
    "    .withColumn(\"averagePoints\", F.round(F.avg(F.col(\"points\")).over(driverWindow), 2))\\\n",
    "    .withColumn(\"maxAvgPoints\", F.max(F.col(\"averagePoints\")).over(seasonWindow))\\\n",
    "    .select(\n",
    "        F.col(\"code\"),\n",
    "        F.sum(F.col(\"points\")).over(driverWindow).alias(\"champPoints\"),\n",
    "        F.col(\"averagePoints\"),\n",
    "        F.round(F.col(\"averagePoints\") / F.col(\"maxAvgPoints\"),2).alias(\"pointPercent\"),\n",
    "        F.sum(F.col(\"podium\")).over(driverWindow).alias(\"totalPodiums\"),\n",
    "        F.round(F.sum(F.col(\"podium\")).over(driverWindow) / F.count(F.col(\"podium\")).over(driverWindow), 2).alias(\"podiumPercent\"),\n",
    "        F.round(F.avg(F.col(\"position\") - F.col(\"grid\")).over(driverWindow), 2).alias(\"positionDelta\"),\n",
    "        F.round(F.avg(F.col(\"positionsLost\")).over(driverWindow), 2).alias(\"avgPositionsLost\"),\n",
    "        F.round(F.avg(F.col(\"positionsGained\")).over(driverWindow), 2).alias(\"avgPositionsWon\"),\n",
    "        F.sum(F.col(\"positionsLost\")).over(driverWindow).alias(\"totalPositionsLost\"),\n",
    "        F.sum(F.col(\"positionsGained\")).over(driverWindow).alias(\"totalPositionsWon\"),\n",
    "        F.col(\"lapsLed\"),\n",
    "        F.col(\"percLapsLed\")\\\n",
    "    )\\\n",
    "    .na.fill(0)\\\n",
    "    .dropDuplicates([\"code\"])\\\n",
    "    .sort(F.col(\"avgPositionsLost\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fd2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def current_milli_time():\n",
    "    return round(time.time() * 1000)\n",
    "\n",
    "def run():\n",
    "    start = current_milli_time()\n",
    "    results.collect()\n",
    "    return current_milli_time() - start\n",
    "\n",
    "def average(l):\n",
    "    return sum(l)/len(l)\n",
    "    \n",
    "def time_test():\n",
    "    l = list()\n",
    "    for i in range(1):\n",
    "        l.append(run())\n",
    "    return average(l)\n",
    "\n",
    "res = time_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525a821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
